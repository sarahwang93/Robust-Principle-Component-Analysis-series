{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation of MFRPCA \n",
    "from scipy import linalg\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# O = B + M, M = E + F \n",
    "# the size of O is height * width * frame_number\n",
    "# the size of B, M, E, F, X, Y is height * width * frame_number\n",
    "# parameter of algorithm includes mu, rho\n",
    "\n",
    "def cal_df(input_frame: np.ndarray, x, y, t):\n",
    "    # the shape of Fh, Fv and Ft, should be 580 * 1920 * 5\n",
    "    fill_up_h = np.zeros((150, 100, 10))\n",
    "    Fh = input_frame[x+1, y, t] - input_frame[x, y, t]\n",
    "    fill_up_v = np.zeros((150, 100, 10))\n",
    "    Fv = input_frame[x, y+1, t] - input_frame[x, y, t]\n",
    "    fill_up_t = np.zeros((150, 100, 10))\n",
    "    Ft = input_frame[x, y, t+1] - input_frame[x, y, t]\n",
    "    fill_up_h[x, y, t] = Fh.item()\n",
    "    fill_up_v[x, y, t] = Fv.item()\n",
    "    fill_up_t[x, y, t] = Ft.item()\n",
    "    Dh = np.ones((1, 150 * 100 * 10))\n",
    "    Dh = fill_up_h.reshape(1, 150 * 100 * 10)\n",
    "    Dv = fill_up_v.reshape(1, 150 * 100 * 10)\n",
    "    Dt = fill_up_t.reshape(1, 150 * 100 * 10)\n",
    "    Dhf = np.transpose(Dh)\n",
    "    #print(Dhf.shape)\n",
    "    Dvf = np.transpose(Dv)\n",
    "    Dtf = np.transpose(Dt)\n",
    "    inner = np.stack((Dhf, Dvf, Dtf))\n",
    "    Df = np.transpose(inner)\n",
    "    #print(Df.shape)\n",
    "    return Df, Dh, Dv, Dt, Dhf, Dvf, Dtf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_RGB(input_img):\n",
    "    if input_img.ndim == 2 or (input_img.ndim==3 and input_img.shape[2] ==1):\n",
    "        # your image is in grayscale\n",
    "        input_img = color.gray2rgb(input_img)\n",
    "    elif input_img.ndim==3 and input_img.shape[2] == 4:\n",
    "        # your image is in RGBA\n",
    "        input_img = color.rgba2rgb(input_img)\n",
    "    else:\n",
    "        # your image is already in RGB\n",
    "        assert input_img.ndim == 3 and input_img.shape[2] == 3\n",
    "    return input_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 480, 720)\n",
      "torch.Size([150, 100, 10])\n",
      "(480, 640, 3)\n",
      "(480, 640)\n",
      "(array([[[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]]]), array([[0., 0., 0., ..., 0., 0., 0.]]), array([[0., 0., 0., ..., 0., 0., 0.]]), array([[0., 0., 0., ..., 0., 0., 0.]]), array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       ...,\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]]), array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       ...,\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]]), array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       ...,\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]]))\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from skimage import color, io\n",
    "\n",
    "# test video segments \n",
    "def read_video_cv2(n_frames=10):\n",
    "    cap = cv2.VideoCapture(\"./survelliance/09152008flight2tape1_7.mpg\")\n",
    "    all = []\n",
    "    i = 0\n",
    "    while cap.isOpened() and i < n_frames:\n",
    "        ret, frame = cap.read()\n",
    "        img = color.rgb2gray(frame)\n",
    "        arr = np.array(img)\n",
    "        all.append(arr)\n",
    "        i += 1\n",
    "    return np.array(all)\n",
    "\n",
    "input_frame = read_video_cv2()\n",
    "print(input_frame.shape)\n",
    "input_seg = torch.tensor(read_video_cv2()).reshape(480, 720, 10)\n",
    "input_seg_new = input_seg[0:150, 0:100, :]\n",
    "print(input_seg_new.shape)\n",
    "\n",
    "img = io.imread('./survelliance/0325.jpg')\n",
    "img_res = convert_RGB(img)\n",
    "print(img.shape)\n",
    "#input\n",
    "imgGray = color.rgb2gray(img_res)\n",
    "print(imgGray.shape)\n",
    "\n",
    "# O represents the height, width and dt frames \n",
    "# B represents the static background \n",
    "O = input_seg_new\n",
    "B = np.ones((150, 100, 10)) \n",
    "# M represents the remaining parts\n",
    "M = np.ones((150, 100, 10))\n",
    "# E represents intrinsic foreground\n",
    "E = np.ones((150, 100, 10))\n",
    "# F represents dynamic background\n",
    "F = np.ones((150, 100, 10))\n",
    "# X and Y represent multiplier\n",
    "x = np.ones((150, 100, 10))\n",
    "y = np.ones((150, 100, 10))\n",
    "# Z and K\n",
    "Z = np.ones((3, 150, 100, 10, 1))\n",
    "K = np.ones((3, 150, 100, 10, 1))\n",
    "\n",
    "def convert_RGB(input_img):\n",
    "    if input_img.ndim == 2 or (input_img.ndim==3 and input_img.shape[2] ==1):\n",
    "        # your image is in grayscale\n",
    "        input_img = color.gray2rgb(input_img)\n",
    "    elif input_img.ndim==3 and input_img.shape[2] == 4:\n",
    "        # your image is in RGBA\n",
    "        input_img = color.rgba2rgb(input_img)\n",
    "    else:\n",
    "        # your image is already in RGB\n",
    "        assert input_img.ndim == 3 and input_img.shape[2] == 3\n",
    "    return input_img\n",
    "\n",
    "def optimization(B, M, E, Df):\n",
    "    res = linalg.norm(B, ord='nuc') + lambda1 * linalg.norm(M, ord=1) + lambda2 * linalg.norm(E, ord=1) + lambda3 * linalg.norm(Df, ord=0)\n",
    "    return res\n",
    "\n",
    "Df_res = cal_df(input_seg, 5, 10, 2)\n",
    "print(Df_res)\n",
    "# optimization(B, M, E, Df_res)\n",
    "\n",
    "def shrinkage_operator(x, epsilon):\n",
    "    # the shape of x is 1080 * 1920\n",
    "    epsilon = np.zeros((150, 100))\n",
    "    para1 = np.sign(x)\n",
    "    print(para1.shape)\n",
    "    para2 = np.maximum((np.fabs(x)-epsilon), np.zeros((150, 100)))\n",
    "    print(para2.shape)\n",
    "    return np.multiply(para1, para2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]]),\n",
       " array([[0., 0., 0., ..., 0., 0., 0.]]),\n",
       " array([[0., 0., 0., ..., 0., 0., 0.]]),\n",
       " array([[0., 0., 0., ..., 0., 0., 0.]]),\n",
       " array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]),\n",
       " array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]),\n",
       " array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_df(input_seg_new, 10, 8, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]]]), array([[0., 0., 0., ..., 0., 0., 0.]]), array([[0., 0., 0., ..., 0., 0., 0.]]), array([[0., 0., 0., ..., 0., 0., 0.]]), array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       ...,\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]]), array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       ...,\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]]), array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       ...,\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]]))\n"
     ]
    }
   ],
   "source": [
    "Df_res = cal_df(input_seg, 5, 10, 2)\n",
    "print(Df_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([150, 100])\n",
      "torch.Size([150, 100])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0157, 0.1725, 0.4051,  ..., 0.3367, 0.3250, 0.3250],\n",
       "        [0.0174, 0.1712, 0.4379,  ..., 0.3267, 0.3300, 0.3227],\n",
       "        [0.0157, 0.1725, 0.4247,  ..., 0.3524, 0.3289, 0.3171],\n",
       "        ...,\n",
       "        [0.0140, 0.1695, 0.4800,  ..., 0.3968, 0.3990, 0.3911],\n",
       "        [0.0039, 0.1569, 0.4695,  ..., 0.3794, 0.3715, 0.3715],\n",
       "        [0.0000, 0.1499, 0.4573,  ..., 0.3724, 0.3488, 0.3567]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shrinkage_operator(input_seg_new[:, :, 0:1].reshape(150, 100), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd =  np.linalg.svd(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "mu = 0.01 \n",
    "lambda1 = 10 \n",
    "lambda2 = 10\n",
    "lambda3 = 10 \n",
    "\n",
    "# isotropic total variation of F. Total\n",
    "def augmentated_lagrangian(O, B, E, Df, F, M, X, Y):\n",
    "    opt = tf.norm(B, ord='euclidean') + lambda1 * tf.norm(M, ord=1) + lambda2 * tf.norm(E, ord=1) + lambda3 * tf.norm(Df, ord=1)\n",
    "    lang1 = mu/2 * (tf.norm(np.array(O - B - M), ord='euclidean', keepdims=True) ** 2) + np.inner(x, O - B - M)\n",
    "    lang2 = mu/2 * (tf.norm(M - F - E, ord='euclidean') ** 2) + np.inner(y, M - F - E)\n",
    "    return opt + lang1 + lang2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-600251739426>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# in Df, the 3 means there are three dimensions are stacked together from fh,fv and ft\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mDf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m150\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0maugmentated_lagrangian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-3f2de1bc3443>\u001b[0m in \u001b[0;36maugmentated_lagrangian\u001b[0;34m(O, B, E, Df, F, M, X, Y)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0maugmentated_lagrangian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'euclidean'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlambda1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlambda2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlambda3\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mlang1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mO\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mB\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'euclidean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mO\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mB\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mlang2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mF\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'euclidean'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mF\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlang1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlang2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "from keras.backend import set_session\n",
    "from keras.backend import clear_session\n",
    "from keras.backend import get_session\n",
    "import gc\n",
    "\n",
    "def reset_keras():\n",
    "    sess = get_session()\n",
    "    clear_session()\n",
    "    sess.close()\n",
    "    sess = get_session()\n",
    "\n",
    "    try:\n",
    "        del classifier # this is from global space - change this as you need\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    print(gc.collect()) # if it does something you should see a number as output\n",
    "\n",
    "    # use the same config as you used to create the session\n",
    "    config = tf.compat.v1.ConfigProto()\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "    config.gpu_options.visible_device_list = \"0\"\n",
    "    set_session(tf.compat.v1.Session(config=config))\n",
    "\n",
    "\n",
    "# sess = tf.Session(config=tf.ConfigProto(log_device_placement=True, gpu_options=gpu_options))\n",
    "\n",
    "\n",
    "# in Df, the 3 means there are three dimensions are stacked together from fh,fv and ft\n",
    "Df = np.zeros((3, 150 * 100 * 10, 1))\n",
    "augmentated_lagrangian(O, B, E, Df, F, M, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shrinkage_operator_diagnal(x, epsilon):\n",
    "    # the shape of x is 1080 * 1920\n",
    "    epsilon = np.ones((150, 100, 10), dtype=np.float32)\n",
    "    para1 = np.sign(x)\n",
    "    # print(type(x))\n",
    "    para2 = np.maximum((tf.math.abs(x)-epsilon), np.zeros((150, 100, 10), dtype=np.float32))\n",
    "    return np.multiply(para1, para2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrinkage_operator_diagnal(O, lambda1/(2 * (mu))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse.linalg as linalg\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "\n",
    "input_seg_new = np.ones((150, 100, 10))\n",
    "L = np.ones((10, 10))\n",
    "for i in range(0, 10):\n",
    "    for j in range(0, 10):\n",
    "        if i == j:\n",
    "            L[i][j] = 0.5\n",
    "\n",
    "# the input of t_svd should be the size of 30 * 20 * 10 \n",
    "# the result of decomposition should be U = 30 * 30 * 10 \n",
    "# S = 30 * 20 * 10, V = 20 * 20 * 10\n",
    "# size of L is f * f\n",
    "import scipy\n",
    "\n",
    "def t_svd(input_tube, h, w, f):\n",
    "    u = np.zeros((h, h, f))\n",
    "    s = np.zeros((h, w, f))\n",
    "    v = np.zeros((w, w, f))\n",
    "    u_hat = np.zeros((h, h, f))\n",
    "    s_hat = np.zeros((h, w, f))\n",
    "    v_hat = np.zeros((w, w, f))\n",
    "    L_reverse = np.linalg.inv(L)\n",
    "    A_hat = tf.matmul(input_tube, L)\n",
    "    for it in range(0, f):\n",
    "        matrix = A_hat[:, :, it]\n",
    "        u, s, v = tf.linalg.svd(matrix, full_matrices = False)\n",
    "        # u_hat[:, :, it] = u\n",
    "        s_hat[:, :, it] = s\n",
    "        v_hat[:, :, it] = v\n",
    "    # [20, ] todo: the size of u_decompose is not correct. \n",
    "    u_decompose = tf.matmul(u_hat, L_reverse)\n",
    "    # 30 * 20 * 10\n",
    "    s_decompose = tf.matmul(s_hat, L_reverse)\n",
    "    # 20 * 20 * 10\n",
    "    v_decompose = tf.matmul(v_hat, L_reverse)\n",
    "    return u_decompose, s_decompose, v_decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_high, singular_high, right_high = t_svd(input_seg_new, 150, 100, 10) \n",
    "print(left_high.shape)\n",
    "print(singular_high.shape)\n",
    "print(right_high.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import tensorly.decomposition as decomposition\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "\n",
    "np_config.enable_numpy_behavior()\n",
    "\n",
    "mu = 0.1\n",
    "# 3-rank tensor multiplication\n",
    "def update_B(O, M, X, mu):\n",
    "    B_mid = np.zeros((O.shape[0], O.shape[1], O.shape[2]))\n",
    "    B_next = np.zeros((O.shape[0], O.shape[1], O.shape[2]))\n",
    "    rank = 10\n",
    "    u1, d1, voft1 = t_svd(O - M + (1/mu) * X, 150, 100 ,10)\n",
    "    for i in range(0, 10):\n",
    "        B_mid[:, :, i] = tf.matmul(u1[:, :, i], shrinkage_operator_diagnal(d1, 1/mu)[:, :, i])\n",
    "        B_next[:, :, i] = tf.matmul(B_mid[:, :, i], voft1[:, :, i])\n",
    "        \n",
    "    return B_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_B(O, M, x, mu).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(B.shape)\n",
    "def update_M(O, B_next, E, F, X, Y, mu):\n",
    "    param = (O - B_next + E + F)/2 + (X - Y)/(2 * (mu))\n",
    "    M_next = shrinkage_operator_diagnal(param, lambda1/(2 * (mu)))\n",
    "    return M_next "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_M(O, B, E, F, x, y, mu).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_E(M_next, F, Y, mu):\n",
    "    param = (M_next - F + 1/(mu) * Y)\n",
    "    E_next = shrinkage_operator_diagnal(param, lambda2/(mu))\n",
    "    return E_next "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_E(M, F, y, mu).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  argmin typically used to find the smallest possible values given constraints\n",
    "#  Unable to allocate 890. GiB for an array with shape (480, 720, 480, 720) and data type float64\n",
    "# the video size is over large\n",
    "def update_F(Df, Y, M_next, E_next, F):\n",
    "    F_next = lambda3 * linalg.norm(Df, ord = 0) + np.inner(Y, M_next - E_next - F) + mu/2 * (tf.norm(M_next - E_next - F, ord=\"euclidean\") ** 2)\n",
    "    return F_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def update_multiplier(X, Y, O, B_next, M_next, E_next, F_next, mu):\n",
    "    X_next = torch.tensor(x) + mu * torch.tensor(O - B_next - M_next)\n",
    "    Y_next = torch.tensor(y) + mu * torch.tensor(M_next - E_next - F_next)\n",
    "    return X_next, Y_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_multiplier(x, y, O, B, M, E, F, mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "dv = 100\n",
    "dh = 50\n",
    "dt = 10\n",
    "\n",
    "Dh = np.ones((dv * dh * dt, dv * dh * dt)).astype(np.int)\n",
    "\n",
    "# the parameter of 3D fourier could change \n",
    "def three_D_fourier(input_matrix):\n",
    "    fft_3D = scipy.fft.fftn(input_matrix)\n",
    "    return fft_3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_D_fourier(Dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = np.zeros((3 * 30 * 20 * 10, 30 * 20 * 10)) \n",
    "K_small = np.ones((3 * 30 * 20 * 10, 1))\n",
    "Z_small = np.ones((3 * 30 * 20 * 10, 1))\n",
    "M_small = np.ones((30, 20, 10))\n",
    "E_small = np.ones((30, 20, 10))\n",
    "y_small = np.ones((30, 20, 10))\n",
    "\n",
    "# todo: the size of Q should be diagnal ----------------? \n",
    "mu = 1 \n",
    "def cal_val_Q(M_next, E_next, y, D, K, Z):\n",
    "    Q = np.array(M_next - E_next + y/mu).reshape(6000, 1) * mu + np.array(gamma * (np.matmul(np.transpose(D), K) + np.matmul(np.transpose(D), Z)/mu)) \n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 5\n",
    "# test-only\n",
    "# work well \n",
    "# result shape is 480 * 720 * 10\n",
    "Q_res = cal_val_Q(M_small, E_small, y_small, D, K_small, Z_small)\n",
    "\n",
    "Q_reshape = Q_res.reshape(1, 6000)\n",
    "print(Q_reshape.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 5\n",
    "K = np.ones((3, 30 * 20 * 10, 1))\n",
    "Z = np.ones((3, 30 * 20 * 10, 1))\n",
    "Df = np.zeros((3, 30 * 20 * 10, 1))\n",
    "\n",
    "'''\n",
    "The shape of inner product in Ft_next_1 is 480 * 720 * 480 * 720 \n",
    "returned results of above should be matching the size of each component\n",
    "'''\n",
    "\n",
    "# todo: update F does not work well ----------------------?\n",
    "def update_F(K, Y, M_next, E_next, Z, Df, gamma):\n",
    "    Ft_next_1 = lambda3 * tf.norm(K, ord = 1) + np.inner(Y, M_next - E_next - F) + mu/2 * (tf.norm(M_next - E_next - F, ord='euclidean') ** 2) \n",
    "    Ft_next_2 = np.inner(Z, K - Df) + gamma/2 * (tf.norm(K - Df, ord='euclidean') ** 2)\n",
    "    return Ft_next_1 + Ft_next_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dh = np.ones((1, dv * dh * dt))\n",
    "Dv = np.ones((1, dv * dh * dt))\n",
    "Dt = np.ones((1, dv * dh * dt))\n",
    "\n",
    "Q_reshape.shape \n",
    "# update_F(K, y, M, E, Z, Df, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the correct size of Q should be dv * dh * dt multiply dv * dh * dt\n",
    "# the size of identity matrix is dv * dh * dt multiply dv * dh * dt, 6000 * 6000\n",
    "# the result of algorithm is to reshape the tensor back to 3-D tensor 30 * 20 * 10\n",
    "\n",
    "def update_Ft(Dv, Dh, Dt, Q):\n",
    "    inner_param = three_D_fourier(Q_reshape)/(mu * np.ones((1, 6000)) + gamma * (np.square(three_D_fourier(Dh)) + np.square(three_D_fourier(Dv)) + np.square(three_D_fourier(Dt))))\n",
    "    ft_next = 1/three_D_fourier(inner_param)\n",
    "    return ft_next.reshape(30, 20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(gamma * (np.square(three_D_fourier(Dh)))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_Ft(Dv, Dh, Dt, Q_reshape).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ph ----> dh\n",
    "# pv ----> dv\n",
    "# pt ----> dt\n",
    "Dhf = np.ones((30 * 20 * 10, 1))\n",
    "Dvf = np.ones((30 * 20 * 10, 1))\n",
    "Dtf = np.ones((30 * 20 * 10, 1))\n",
    "Zh = np.ones((30 * 20 * 10, 1))\n",
    "Zv = np.ones((30 * 20 * 10, 1))\n",
    "Zt = np.ones((30 * 20 * 10, 1))\n",
    "Z = np.transpose(np.vstack((np.vstack((np.transpose(Zh),  np.transpose(Zv))), np.transpose(Zt))))\n",
    "print(Z.shape)\n",
    "\n",
    "\n",
    "def solution_ph(Dhf, Zh):\n",
    "    return Dhf - Zh/gamma\n",
    "\n",
    "def solution_pv(Dvf, Zv):\n",
    "    return Dvf - Zv/gamma\n",
    "\n",
    "def solution_pt(Dhf, Zt):\n",
    "    return Dhf - Zt/gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the size of Z and Dhf, Dvf and Dtf should be same\n",
    "ph = solution_ph(Dhf, Z)\n",
    "pv = solution_pv(Dvf, Z)\n",
    "pt = solution_pt(Dtf, Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# in Df, the 3 means there are three dimensions are stacked together from fh,fv and ft\n",
    "Df = np.zeros((3, 30 * 20 * 10, 1))\n",
    "# the shape of variable does not change in any defined t\n",
    "# the shape of Df is same as Dvf, Dhf, Dtf\n",
    "\n",
    "def shrinkage_operator_anisotropic(x, epsilon):\n",
    "    # the shape of x is 1080 * 1920\n",
    "    x = x.reshape(3, 30 * 20 * 10, 1)\n",
    "    epsilon = np.zeros((3, 30 * 20 * 10, 1))\n",
    "    para1 = np.sign(x)\n",
    "    para2 = np.maximum((np.fabs(x)-epsilon), np.zeros((3, 30 * 20 * 10, 1)))\n",
    "    return np.multiply(para1, para2)\n",
    "\n",
    "\n",
    "def update_Kt_anisotropic(Df, Z, gamma):\n",
    "    Df = Df.reshape(3, 30 * 20 * 10, 1)\n",
    "    Z = Z.reshape(3, 30 * 20 * 10, 1)\n",
    "    return shrinkage_operator_anisotropic(Df - (1/gamma * Z), lambda3/gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_Kt_anisotropic(Df, Z, gamma).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_Kt_isotropic(ph, pv, pt):\n",
    "    epsilon = 10\n",
    "    p = np.maximum(np.sqrt(np.square(ph) + np.square(pv) + np.square(pt)), epsilon)\n",
    "    kt_next = np.maximum(p - lambda3/gamma, 0) * ph/p\n",
    "    return kt_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kt = update_Kt_isotropic(ph, pv, pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Df.shape)\n",
    "print(Kt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_Z(Z, Kt_next, Df_next):\n",
    "    Z_next = Z  + gamma * (Kt_next- Df_next)\n",
    "    return Z_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_Z(Z, Kt, Df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.5\n",
    "rho = 1.5\n",
    "\n",
    "def update_gamma(gamma, Kt_next, Df_next, Kt, Df):\n",
    "    if tf.norm(Kt_next - Df_next, ord = 2) >= alpha * tf.norm(Kt - Df, ord = 2): \n",
    "        gamma_next = gamma * rho\n",
    "    else: \n",
    "        gamma_next = gamma\n",
    "    return gamma_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_gamma(gamma, Kt, Df, Kt, Df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "\n",
    "def f_subproblem(Dv, Dh, Dt, Df, option:str, Q, Z, gamma, t):\n",
    "    Ft_next = update_Ft(Dv, Dh, Dt, Q)\n",
    "    if option == \"anisotropic\":\n",
    "        Kt_next = update_Kt_anisotropic(Df, Z, gamma)\n",
    "    elif option == \"isotropic\":\n",
    "        ph = solution_ph(Dhf, Z)\n",
    "        pv = solution_pv(Dvf, Z)\n",
    "        pt = solution_pt(Dtf, Z)\n",
    "        Kt_next = update_Kt_isotropic(ph, pv, pt)\n",
    "    Kt_next = Kt\n",
    "    Df_next = Df\n",
    "    Z = update_Z(Z, Kt_next, Df_next)\n",
    "    gamma = update_gamma(gamma, Kt_next, Df_next, Kt, Df)\n",
    "    t = t + 1\n",
    "    return Ft_next, Kt_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Df, Dh, Dv, Dt, Dhf, Dvf, Dtf = cal_df(input_seg_new, 10, 8, 5)\n",
    "# F_next, K_next = f_subproblem(Dv, Dh, Dt, Df, \"anisotropic\", Q_reshape, Z, gamma, t)\n",
    "\n",
    "F_next1, K_next1 = f_subproblem(Dv, Dh, Dt, Df, \"anisotropic\", Q_reshape, Z, gamma, t)\n",
    "F_next2, K_next2 = f_subproblem(Dv, Dh, Dt, Df, \"isotropic\", Q_reshape, Z, gamma, t)\n",
    "# result of anisotropic\n",
    "print(F_next1.shape)\n",
    "print(K_next1.shape)\n",
    "\n",
    "# result of isotropic\n",
    "print(F_next2.shape)\n",
    "print(K_next2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tvrpca(O, B, M, E, F, X, Y, Z, K, option, Q):\n",
    "    mu = 0.1\n",
    "    rho = 2\n",
    "    k = 0\n",
    "    iter_num = 1\n",
    "    t = 0\n",
    "    gamma = 5\n",
    "    alpha = 0.5\n",
    "    while iter_num < 20:\n",
    "        print(\"This is \" + str(iter_num) + \"th iteration\")\n",
    "        B = update_B(O, M, X, mu)\n",
    "        # B_next = np.ones((30, 20, 10))\n",
    "        M = update_M(O, B, E, F, X, Y, mu)\n",
    "        E = update_E(M, F, Y, mu)\n",
    "        F, K = f_subproblem(Dv, Dh, Dt, Df, option, Q, Z, gamma, t)\n",
    "        #F = np.ones((30, 20, 10))\n",
    "        X, Y = update_multiplier(X, Y, O, B, M, E, F, mu)\n",
    "        k = k + 1\n",
    "        mu = mu * rho\n",
    "        iter_num += 1\n",
    "        terminate_flag = (tf.norm(O - B - F - E, ord='euclidean')).numpy() ** 2 <= 10 ** (-7) * ((tf.norm(O, ord = 'euclidean') ** 2)).numpy()\n",
    "        if terminate_flag == True:\n",
    "            break\n",
    "    return B, F, E, M\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.norm(O - B - F - E, ord='euclidean') ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_res, F_res, E_res, M_res = tvrpca(O, B, M, E, F, x, y, Z, K, 'anisotropic', Q_reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "print(B_res.shape)\n",
    "im_output_sparse = Image.fromarray(F_res[:, :, 0].astype(np.uint8))\n",
    "if im_output_sparse.mode != 'RGB':\n",
    "    im_output_rank = im_output_sparse.convert('RGB')\n",
    "im_output_rank.save(\"./res/tvrpca.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
