{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 480, 720)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from skimage import color\n",
    "\n",
    "def read_video_cv2(n_frames=10):\n",
    "    cap = cv2.VideoCapture(\"./survelliance/09152008flight2tape1_7.mpg\")\n",
    "    all = []\n",
    "    i = 0\n",
    "    while cap.isOpened() and i < n_frames:\n",
    "        ret, frame = cap.read()\n",
    "        img = color.rgb2gray(frame)\n",
    "        arr = np.array(img)\n",
    "        all.append(arr)\n",
    "        i += 1\n",
    "    return np.array(all)\n",
    "\n",
    "video_seg = read_video_cv2()\n",
    "print(video_seg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "u, d, v = scipy.sparse.linalg.svds(video_seg[0], k=3)\n",
    "print(d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 720)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the shape of B\n",
    "B0 = np.matmul(u, v)\n",
    "B0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I denotes the jth frame in sequence, where each I is a column vector with m pixels\n",
    "m = 480\n",
    "n = 720\n",
    "p1 = 6\n",
    "p2 = 8\n",
    "D = np.ones((m, n))\n",
    "B = np.ones((m, n))\n",
    "S = np.ones((m, n))\n",
    "tau = np.ones((1, p1))\n",
    "each_I = np.transpose(np.ones((1, m)))\n",
    "B_hat = np.ones((m, n))\n",
    "S_hat = np.ones((1, n))\n",
    "\n",
    "\n",
    "def c_subsolution(D, B_hat):\n",
    "    c_sum = 0\n",
    "    for i in range(0, D.shape[0]):\n",
    "        for j in range(0, D.shape[1]):\n",
    "            c_sum += 0.5 *((D[i][j] - B_hat[i][j]) ** 2)\n",
    "    return c_sum\n",
    "\n",
    "c_subsolution(D, B_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def B_hat_estimate(D, B_hat, alpha):\n",
    "    B_hat = singular_threshold(com_projection(I, D, S_hat) + orthogonal_projection(B_hat, S_hat), alpha)\n",
    "    return B_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 480)\n"
     ]
    }
   ],
   "source": [
    "I = np.identity(m)\n",
    "\n",
    "# complementary projector \n",
    "# x = complementary(X, S) + orthogonal_projection(X, S)\n",
    "def com_projection(identity, input_matrix, subspace):\n",
    "    P = np.matmul(input_matrix, np.transpose(input_matrix))\n",
    "    print(P.shape)\n",
    "    return identity - P\n",
    "\n",
    "com_pro = com_projection(I, D, S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1dd41e51bb2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m720\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mS_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m720\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m720\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mS_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "n = 720\n",
    "S_hat = np.ones((1, 720))\n",
    "torch.tensor((np.dot(B[4].reshape((1, 720)), np.transpose(S_hat))/np.tensordot(S_hat, S_hat)) * S_hat).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480\n",
      "(480, 720)\n"
     ]
    }
   ],
   "source": [
    "# it represents the orthogonal projection of matrix X onto linear space of matrices supported by S_hat\n",
    "# S_hat is the subspace\n",
    "\n",
    "B = np.ones((480, 720))\n",
    "S_hat = np.ones((1, 720))\n",
    "\n",
    "def orthogonal_projection(B, S_hat):\n",
    "    # each row in B is a vector \n",
    "    vector_space = []\n",
    "    print(len(B))\n",
    "    for i in range(0, len(B)):\n",
    "        each_projector = (np.matmul(B[i].reshape((1, 720)), np.transpose(S_hat))/np.tensordot(S_hat, S_hat)) * S_hat\n",
    "        vector_space.append(each_projector)\n",
    "    return vector_space\n",
    "\n",
    "oth_projector = np.array(orthogonal_projection(B, S_hat)).reshape(480, 720)\n",
    "print(np.array(B-oth_projector).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 720)\n"
     ]
    }
   ],
   "source": [
    "def orthogonal_projection_try(B, S_hat):\n",
    "    return (np.tensordot(B, S_hat)/np.tensordot(S_hat, S_hat)) * S_hat\n",
    "\n",
    "B = np.ones((480, 720))\n",
    "S_hat = np.ones((480, 720))\n",
    "print(orthogonal_projection_try(B, S_hat).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(480, 1, 720)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(orthogonal_projection(D, S_hat)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(B[0].reshape(1, 720), np.transpose(S_hat))/np.tensordot(S_hat, S_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# shape of each_D is m * 1 \n",
    "# shape of tau is 1 * p1\n",
    "# the shape of B_hat is m * p1\n",
    "each_D = np.ones((m, 1))\n",
    "each_tau = np.ones((1, p1))\n",
    "def cal_B_hat(each_D, each_tau):\n",
    "    B_hat = []\n",
    "    for i in range(0, n):\n",
    "        each_column = np.matmul(each_D, each_tau)\n",
    "        B_hat.append(each_column)\n",
    "    return B_hat\n",
    "    \n",
    "res = cal_B_hat(each_D, each_tau)\n",
    "print(torch.tensor(res).shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighted least squares \n",
    "import torch\n",
    "from torch.autograd.functional import jacobian\n",
    "import tensorflow as tf\n",
    "\n",
    "rank = 3\n",
    "\n",
    "tau = np.ones((p1, 30))\n",
    "\n",
    "# the first parameter is the shape of B_hat m * p \n",
    "# the second paramter is the shape of tau \n",
    "def wls_subproblem(com_projector, input_tau):\n",
    "    input_weighted = tf.norm(com_projector, ord=2) ** 2\n",
    "    param = input_tau\n",
    "    return torch.linalg.lstsq(torch.tensor(input_weighted), torch.tensor(param), rcond=None, driver='gels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345482.45449234475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(690966.9090, dtype=torch.float64, grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd.functional import jacobian\n",
    "\n",
    "# manipulate tau onto D, the result is still 480 * 720\n",
    "tau_hat = np.linalg.norm(singular_threshold(D_parameterized - B_hat, rank, alpha), ord='fro') ** 2\n",
    "\n",
    "print(tau_hat)\n",
    "\n",
    "def relation_exp(tau):\n",
    "    return tau * 2 + tau * tau\n",
    "\n",
    "def cal_jacobian(inputs):\n",
    "    return jacobian(relation_exp,  torch.tensor(inputs), create_graph=True)\n",
    "\n",
    "cal_jacobian(tau_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 480)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "com_projection(I, D_parameterized, S_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.029514034008903386"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def estimate_delta(D, B_hat):\n",
    "    input_var = np.subtract(D, B_hat)\n",
    "    squared_delta = np.var(input_var)\n",
    "    return squared_delta\n",
    "\n",
    "estimate_delta(D, B_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 21.75750116,   0.        ,   0.        ],\n",
       "       [  0.        ,  30.9118654 ,   0.        ],\n",
       "       [  0.        ,   0.        , 226.87020831]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_diagonal_alpha(input_dia, rank, alpha):\n",
    "    res = np.zeros((rank, rank))\n",
    "    for i in range(0, rank):\n",
    "        for j in range(0, rank):\n",
    "            if i == j: \n",
    "                res[i][j] = input_dia[i] - alpha\n",
    "    return res\n",
    "\n",
    "convert_diagonal_alpha(d, 3, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 720)\n"
     ]
    }
   ],
   "source": [
    "def cal_s_hat(S_hat):\n",
    "    S_hat = np.zeros((S_hat.shape[0], S_hat.shape[1]))\n",
    "    \n",
    "    for i in range(0, S_hat.shape[0]):\n",
    "        for j in range(0, S_hat.shape[1]):\n",
    "            if 0.5 * ((D[i][j] - B_hat[i][j]) ** 2) > beta:\n",
    "                S_hat[i][j] = 1\n",
    "    \n",
    "    return S_hat\n",
    "\n",
    "Sparse_hat = cal_s_hat(S_hat)    \n",
    "print(Sparse_hat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 720)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "beta = 2\n",
    "\n",
    "# A is the adjacency matrix of graph with m * n\n",
    "m = 480\n",
    "n = 720\n",
    "A = np.ones((m, n))\n",
    "print(S.shape)\n",
    "def energy_optimization(D, B_hat, S, A):\n",
    "    energy_sum = 0\n",
    "    for i in range(0, m):\n",
    "        for j in range(0, n):\n",
    "            tmp1 = (D[i][j] - B_hat[i][j])**2\n",
    "            mid = beta - 0.5 * tmp1\n",
    "            tmp2 = mid * S[i][j]\n",
    "            energy_sum += tmp2\n",
    "            \n",
    "    C = c_subsolution(D, B_hat)\n",
    "    print(\"shape A: \" + str(A.shape))\n",
    "    print(\"shape S: \" + str(S.shape))\n",
    "    return energy_sum + gamma1 * tf.norm(np.matmul(A, np.vectorize(S)), ord=1) + C "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 480)\n",
      "(480, 720)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# the operator of each D and each tau is the transformation parameterization\n",
    "# B is low-rank, E is intensity shift by outliers, epsilon is gaussian noise \n",
    "def dot_operator(D, tau_vec):\n",
    "    new_D = []\n",
    "    for i in range(0, n):\n",
    "        new_D_re = []\n",
    "        D_re = D[:, i].reshape(1, 480)\n",
    "        # recycle dot product\n",
    "        for j in range(0, 480, 6):\n",
    "            param_D = np.multiply(D_re[:, j:j+6], tau_vec)\n",
    "            new_D_re.append(param_D)\n",
    "        new_D.append(np.array(new_D_re).flatten())\n",
    "        D[:, i] = B[:, i] + E[:, i] + epsilon[:, i]\n",
    "    print(np.array(new_D).shape)\n",
    "    return np.transpose(new_D)\n",
    "\n",
    "tau_each = np.ones((1, 6))\n",
    "D_parameterized = dot_operator(D, tau_each)\n",
    "print(D_parameterized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of tau is (p * n, 1)\n",
    "tau_hat = tf.norm(com_projection(I, dot_operator(D, tau) - B_hat, S_hat), ord='euclidean')\n",
    "print(tau_hat)\n",
    "K = np.sqrt(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma1 = beta\n",
    "gamma2 = 5*beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def singular_threshold(input_matrix, rank, alpha):\n",
    "    u, d, voft = scipy.sparse.linalg.svds(input_matrix, k=rank)\n",
    "    diag_alpha = convert_diagonal_alpha(d, rank, alpha) \n",
    "    return np.matmul(np.matmul(u, diag_alpha), voft)\n",
    "\n",
    "\n",
    "def get_rank_b(B):\n",
    "    return tf.norm(B, ord='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 720)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "singular_threshold(D, 3, 0.5).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rank_b(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 480)\n",
      "(480, 720)\n",
      "(1, 6)\n"
     ]
    }
   ],
   "source": [
    "print((dot_operator(D, tau) - B_hat).shape)\n",
    "print(tau.shape)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rank(input_matrix):\n",
    "    return np.linalg.matrix_rank(input_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-196-2a502730c665>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-196-2a502730c665>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def weight_lease_square()\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def weight_lease_square()\n",
    "\n",
    "def wls_subproblem(input_projection, tau_para)\n",
    "    return tau_para\n",
    "    \n",
    "def cal_jacobian(input_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-558ca10b0989>, line 47)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-558ca10b0989>\"\u001b[0;36m, line \u001b[0;32m47\u001b[0m\n\u001b[0;31m    jacobian_pro =\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "image_input = video_seg[0]\n",
    "m = video_seg[0].shape[0]\n",
    "m = 30\n",
    "n = video_seg[0].shape[1]\n",
    "n = 720\n",
    "# initialization \n",
    "D = image_input\n",
    "B = np.zeros((image_input.shape[0], image_input.shape[1]))\n",
    "B_hat = np.ones((480, 720))\n",
    "E = np.zeros((image_input.shape[0], image_input.shape[1]))\n",
    "epsilon = np.zeros((image_input.shape[0], image_input.shape[1]))\n",
    "p1 = 6\n",
    "p2 = 8\n",
    "S_hat = np.ones((480, 720))\n",
    "alpha = 0.1\n",
    "beta = 0.1 \n",
    "tau = np.zeros((1, p1))\n",
    "increased_tau = np.ones((1, p1))\n",
    "K = np.sqrt(n)\n",
    "gamma = beta\n",
    "eta1 = 1/np.sqrt(2)\n",
    "eta2 = 0.5\n",
    "\n",
    "\n",
    "    \n",
    "def decolor(D, tau, B_hat, S_hat, rank, alpha):\n",
    "    # ord is 2 or fro \n",
    "    tau_hat = np.ones((1, p1*n))\n",
    "    delta_hat = 0.5\n",
    "    increased_tau = np.ones((1, p1*n))\n",
    "    iter_num = 0\n",
    "    beta = 0.1\n",
    "    while iter_num < 25:\n",
    "        print(iter_num)\n",
    "        # to-do: the wls problem is to get the increased_tau\n",
    "        # should be two ways to calculate complementary projection\n",
    "        projection_inner = dot_operator(D, tau) - B_hat\n",
    "        sub_projection = orthogonal_projection_try(dot_operator(D, tau) - B_hat, S_hat)\n",
    "        com_projection = projection_inner - sub_projection\n",
    "        increased_tau = wls_subproblem(tf.norm(com_projection, ord=2) ** 2, increased_tau)\n",
    "        tau_hat = tau_hat + increased_tau\n",
    "        if get_rank(B_hat) <= K:\n",
    "            alpha = eta1 * alpha\n",
    "            # size of B_hat is(480, 720)\n",
    "            jacobian_pro = \n",
    "            B_hat = singular_threshold(com_projection(I, dot_operator(D, tau) - jacobian_pro, S_hat) + orthogonal_projection_try(B_hat, S_hat), rank, alpha)\n",
    "        iter_num += 1\n",
    "        delta_est = estimate_delta(D, B_hat)\n",
    "        beta = np.max((eta2 * beta, 4.5 * ((delta_hat)**2)))\n",
    "        # todo: the index of S is changable? \n",
    "        S_hat = (beta - 0.5 * (np.subtract(dot_operator(D, tau), B_hat) ** 2)) * S + gamma * tf.norm(np.matmul(A, np.transpose(S[0])), ord=1)\n",
    "    \n",
    "    return B_hat, S_hat, tau_hat\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'orthogonal_projection_try' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8d2e60764018>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0morthogonal_projection_try\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_operator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mB_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'orthogonal_projection_try' is not defined"
     ]
    }
   ],
   "source": [
    "orthogonal_projection_try(dot_operator(D, tau) - B_hat, S_hat).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(720, 480)\n",
      "(720, 480)\n",
      "(720, 480)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'jacobian_pro' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-199-d579b350ad6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdecolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-197-72262d454d87>\u001b[0m in \u001b[0;36mdecolor\u001b[0;34m(D, tau, B_hat, S_hat, rank, alpha)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;31m# size of B_hat is(480, 720)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;31m# jacobian_pro =\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mB_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msingular_threshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcom_projection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdot_operator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mjacobian_pro\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS_hat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morthogonal_projection_try\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0miter_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mdelta_est\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimate_delta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'jacobian_pro' is not defined"
     ]
    }
   ],
   "source": [
    "decolor(D, tau, B_hat, S_hat, rank, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor((np.dot(B[4].reshape((1, 720)), np.transpose(S_hat))/np.tensordot(S_hat, S_hat)) * S_hat).shape\n",
    "print(len(orthogonal_projection(B_hat, S_hat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
